#!/usr/bin/env python


##### ##### ##### ##### ##### ##### ##### #####
#                                             #
#                graftM v.0.2.1               #
#                                             #
#        This is a script for doing the       #
#       gene centric analyses in Joel's       #
#               Honours project.              #
#                                             #
##### ##### ##### ##### ##### ##### ##### #####

##### Messsages #####
intro = '''
    ## graftM  v.0.2.1                   ##
    ## Searches raw sequences for genes  ##
    ## Joel Boyd, Honours 2014           ##
                                              __/__
                                       ______|
- - _                         ________|      |_____/
- -            -             |        |____/_
- _     --->  -   --->   ____|      ______
_-  -          -             |_____|
  - _  	    	                   |______
-
'''

import argparse
import re
try:
  from Bio import SeqIO
except ImportError:
  print "Please install Biopython first"
  exit(1)
import glob
import subprocess
from datetime import datetime
import cPickle as pickle
import code
from collections import OrderedDict
import tempfile


##### Input Files #####

parser = argparse.ArgumentParser(description='''--- graftM  v.0.2.1 --- Searches reads for genes using hmms, and places them into a tree with pplacer to classify them phylogenetically.'''
                          , epilog='Joel Boyd - Honours 2014.')
parser.add_argument('-f', metavar = 'forward read (or single read file)', type = str, nargs = 1 , help = 'Forward raw sequence file in .fa, or .fq.gz format.', required = True)
parser.add_argument('-r', metavar = 'reverse read', type = str, nargs = 1, help = 'Optional reverse raw sequence file in .fa, or .fq.gz format.', default = argparse.SUPPRESS)
parser.add_argument('-t', metavar = 'prot or dna', type = str, nargs = 1, help = 'dna (like 16S) or prot (like mcrA)', choices = ['prot','dna'], required = True)
parser.add_argument('-m', metavar = 'hmm_file', type = str, nargs = 1, help = 'HMM file', required = True)
parser.add_argument('-e', metavar = 'evalue', type = str, nargs = 1, help = 'evalue cutoff for the hmmsearch (default = 1e-5)', default = ['1e-5'])
parser.add_argument('-jpplacer', metavar = 'threads', type = str, nargs = 1, help = 'number of threads to use when pplacing (default = 5)', default = [5])
parser.add_argument('-jhmm', metavar = 'threads', type = str, nargs = 1, help = 'number of threads to use when hmmsearching (default = 5)', default = [5])
parser.add_argument('-d', metavar = 'confidence', type = str, nargs = 1, help = 'Cutoff of placement confidence level (0.5 - 1), default = 0.75', default = [0.75])
parser.add_argument('-c', metavar = 'reference_package', type = str, nargs = 1, help = 'Reference package of gene family', default =argparse.SUPPRESS)
parser.add_argument('-g', metavar = 'gg_database', type = str, help = 'Aligned gg database for pynast alignment (dna sequences only)', default = argparse.SUPPRESS)
parser.add_argument('-o', metavar = 'output directory', type = str, nargs = 1, help = 'Specify an output directory (default is the file name) If you are looking for more than one marker gene in the same directory, you will definitely need this flag to avoid clobbering.', default = argparse.SUPPRESS)
parser.add_argument('-v', action = 'version', version = 'graftM v.0.2.1')

cl=parser.parse_args()



# Constants - don't change them evar.
FORMAT_FASTA = 'FORMAT_FASTA'
FORMAT_FASTQ_GZ = 'FORMAT_FASTQ_GZ'
FORMAT_SRA = 'FORMAT_SRA'


##### Functions #####

# Given a Return the guessed file format, or raise an Exception if
def guess_sequence_file_format(sequence_file_path):
  if sequence_file_path.endswith(('.fa','.faa','.fna')): # Check the file type
    return FORMAT_FASTA
  elif sequence_file_path.endswith(('.fq.gz', '.fastq.gz')):
    return FORMAT_FASTQ_GZ
  elif sequence_file_path.endswith(('.sra')):
    return FORMAT_SRA
  else:
    raise Exception("Unable to guess file format of sequence file: %s" % sequence_file_path)

# Corrects sequence alignments by removing lower case insertions
def alignment_correcter(alignment_file, output_file_name):
  rm_list = [] # Define positions to be removed (lower case characters)
  for sequence in list(SeqIO.parse(open(alignment_file, 'r'), 'fasta')): # For each sequence in the alignment
    for idx, nt in enumerate(list(sequence.seq)): # For each nucleotide in the sequence
      if nt.islower(): # Check for lower case character
        rm_list.append(idx) # Add to list if it is
  rm_list = list(OrderedDict.fromkeys(sorted(rm_list, reverse = True))) # Reverse the list and remove duplicate positions
  o = open(output_file_name, 'w')
  for sequence in list(SeqIO.parse(open(alignment_file, 'r'), 'fasta')): # For each sequence in the alignment
    new_seq = list(sequence.seq)
    for position in rm_list: # For each position in the removal list
      del new_seq[position] # Delete that position in every sequence
    o.write('>'+sequence.id+'\n')
    o.write(''.join(new_seq)+'\n')

# Displays message with time in brackets before the message.
def message(message):
  time = datetime.now().strftime('%H:%M:%S')
  print '['+time+']: '+str(message)

# split_names
def title_cleaner(title):
  d = title.split('_')
  del d[-1]
  return '_'.join(d)

# run nhmmer
def nhmmer(hmm, seq_file_list, input_file_format):
  suffix = ['_for', '_rev']
  table_title_list = []
  for seq_file in seq_file_list:
    hmmout_table_title = replace_name(seq_file, suffix[0]+'.hmmout.csv')
    table_title_list.append(hmmout_table_title)
    nhmmer_cmd = "nhmmer "+cl.jhmm[0]+" "+cl.e[0]+" --tblout " +hmmout_table_title+ " " +hmm
    if input_file_format == FORMAT_FASTA:
      subprocess.check_call(["/bin/bash", "-c", nhmmer_cmd+ " <(sed 's/:/$/g' " +seq_file+ ") 2>&1 > /dev/null"])
    elif input_file_format == FORMAT_FASTQ_GZ:
      subprocess.check_call(["/bin/bash", "-c", nhmmer_cmd+ " <(awk '{print \">\" substr($0,2);getline;print;getline;getline}' <(zcat " +seq_file+ " | sed 's/:/$/g')) 2>&1 > /dev/null"])
    elif input_file_format == FORMAT_SRA:
      cmd = "fastq-dump --fasta --stdout %s 2>/dev/null | %s /dev/stdin 2>&1 > /dev/null" % (
        seq_file,
        nhmmer_cmd
      )
      subprocess.check_call(cmd, shell=True)
    else:
      message('ERROR: Suffix on %s not recegnised. Please submit an .fq.gz or .fa file\n' % (seq_file))
      exit(1)
    del suffix[0]
  return table_title_list

# run hmmsearch
def hmmsearch(hmm, seq_file_list, input_file_format):
  suffix = ['_for', '_rev']
  table_title_list = []
  for seq_file in seq_file_list:
    hmmout_table_title = replace_name(seq_file, suffix[0]+'.hmmout.csv')
    table_title_list.append(hmmout_table_title)
    hmmsearch_cmd = " hmmsearch "+cl.jhmm[0]+" "+cl.e[0]+" -o /dev/null --domtblout " +hmmout_table_title+ " " +hmm+ " "
    #TODO: capture stderr and report if the check_call fails
    if input_file_format == FORMAT_FASTA:
      subprocess.check_call(["/bin/bash", "-c", hmmsearch_cmd+" <(getorf -sequence  <(sed 's/:/$/g' " +seq_file+ ") -outseq >(cat) -minsize 98 2>/dev/null) 2>&1 > /dev/null"])
    elif input_file_format == FORMAT_FASTQ_GZ:
      subprocess.check_call(["/bin/bash", "-c", hmmsearch_cmd+" <(getorf -sequence <(awk '{print \">\" substr($0,2);getline;print;getline;getline}' <(zcat " +seq_file+ " | sed 's/:/$/g')) -outseq >(cat) -minsize 98 2>/dev/null) 2>&1 > /dev/null"])
    elif input_file_format == FORMAT_SRA:
      cmd = "fastq-dump --fasta --stdout %s 2>/dev/null |getorf -sequence /dev/stdin -outseq /dev/stdout -minsize 98 2>/dev/null | %s /dev/stdin &>/dev/null" % (
        seq_file,
        hmmsearch_cmd
        )
      subprocess.check_call(cmd)

    else:
      message('ERROR: Suffix on %s not recegnised\n' % (seq_file))
      exit(1)
    del suffix[0]
  return table_title_list

# run pynast
def pynast(ts_file, gg_db_path):
  subprocess.check_call('pynast -l 0 -i ' +replace_name(ts_file, '.fna.fasta')+ ' -t ' +gg_db_path+ ' -a ' +replace_name(ts_file, '.aln.fasta'), shell=True)

# run pplacer
def pplacer(refpkg, ts_file):
  subprocess.check_call('pplacer '+cl.jpplacer[0]+' --verbosity 0 -c ' +refpkg+ ' ' +ts_file, shell=True)

# run guppy classify
def guppy_class(rpkg, jplace_file):
  subprocess.check_call('guppy classify -c ' +rpkg+ ' '+jplace_file+' > ' +replace_name(jplace_file, '.guppy'), shell=True)

# delete
def delete(delete_list):
  for item in delete_list:
    subprocess.check_call("rm "+item, shell = True)

# HMM aligning
def hmmalign(hmm, sequencefile):
  base_name = replace_name(sequencefile, '') # Create a base name for output files
  subprocess.check_call("mkdir -p "+ cl.o[0], shell=True)
  subprocess.check_call("mv "+base_name+".* "+cl.o[0], shell = True)
  subprocess.check_call('hmmalign --trim -o '+base_name+'.sto ' +hmm+ ' ' +cl.o[0]+ '/' +sequencefile, shell = True)
  subprocess.check_call('seqmagick convert '+base_name+'.sto ' +base_name+ '_conv_.fa', shell=True)

# process hmmsearch/nhmmer results into ts_files
def csv_to_titles(hmm_table_list, type_):
  titles_list = []
  reads_list = []
  write_list = []
  title_count = 0
  for hmm_table in hmm_table_list:
    for line in open(hmm_table):
      if line.startswith('#'):
        continue
      title_count += 1
      title = str(line.split(' ', 1)[0])
      if type_ == 'dna':
        if 'FCC' in line:
          titles_list.append(title.replace('$',':').replace('_', '/')[:-2])
        else:
          titles_list.append(title.replace('$',':'))
      if type_ == 'prot':
        if line.startswith('FCC'):
          titles_list.append(title_cleaner(title).replace('$',':')[:-2])
        else:
          titles_list.append(title_cleaner(title).replace('$',':'))
    reads_list.append(titles_list)
    titles_list = []

  if title_count == 0: # Check if any reads were found
    message('0 Reads found! Exiting..') # If not, throw a warning
    exit(1) # and exit
  else:
    message('Found %s read(s) in %s.' % (str(title_count), replace_name(hmm_table_list[0], ''))) # Otherwise, report the count.

  if len(reads_list) == 2:
    for_r = set(reads_list[0])
    for read in reads_list[1]:
      if read in for_r:
        write_list.append(read)
  elif len(reads_list) == 1:
    write_list = reads_list[0]

  output_file_name = replace_name(hmm_table_list[0], '')[:-3]+'readnames.txt'
  output_file = open(output_file_name, 'w')
  for name in write_list:
    if name.startswith('FCC'):
      output_file.write(name+'/1'+'\n')
    else:
      output_file.write(name+'\n')
  output_file.close()

  return output_file_name

def extract_from_raw_reads(raw_seq_file, hmm, name_file, input_file_format):
  ## Run fxtract to obtain reads form original sequence file
  sequence_file_name = name_file.replace('_readnames.txt', '.fna') # Set the new output file name
  message('Extracting reads..') # Send an update
  fxtract_cmd = "fxtract -H -X -f " +replace_name(raw_seq_file, '_readnames.txt')+ " "
  if input_file_format == FORMAT_FASTA:
    subprocess.check_call(fxtract_cmd+ " " +raw_seq_file+ " > " +sequence_file_name+ " ", shell=True)
  elif input_file_format == FORMAT_FASTQ_GZ:
    subprocess.check_call(fxtract_cmd +raw_seq_file+ " | awk '{print \">\" substr($0,2);getline;print;getline;getline}' > " +sequence_file_name+ " ", shell=True)
  elif input_file_format == FORMAT_SRA:
    # There's no good way to extract sequences directly from the sra
    # file by specifying their ID. So first dump to a temp fasta file,
    # then fxtract from that.
    with tempfile.NamedTemporaryFile() as tmp:
      cmd = "fastq-dump --fasta --stdout %s 2>/dev/null > %s " % (raw_seq_file, tmp.name)
      subprocess.check_call(cmd, shell=True)
      cmd = "%s %s > %s" % (fxtract_cmd, tmp.name, sequence_file_name)
      subprocess.check_call(cmd, shell=True)
  else:
    raise Exception("Programming error")


  alt_title_file_name = replace_name(raw_seq_file, '.fna.fasta')
  fasta_file_open = open(alt_title_file_name, 'w')
  for sequence in list(SeqIO.parse(open(sequence_file_name, 'r'), 'fasta')):
    sequence.id = sequence.id.replace(':', '_')
    SeqIO.write(sequence, fasta_file_open, "fasta")
  fasta_file_open.close()

  if cl.t[0] == 'dna': # Stop here if the pipeline is DNA
    return

  raw_orf_title = replace_name(raw_seq_file, '.orf')
  subprocess.check_call('getorf -sequence ' +alt_title_file_name+ ' -outseq ' +raw_orf_title+ ' -minsize 98 2>/dev/null', shell=True)

  hmm_out_title = replace_name(raw_seq_file, '.tmp.csv')
  subprocess.check_call("hmmsearch --tblout "+hmm_out_title+" "+hmm+" "+raw_orf_title+" 2>&1 > /dev/null", shell=True)

  raw_titles = []
  for line in open(hmm_out_title):
    if line.startswith('#'):
      continue
    split = line.split(' ', 1)
    raw_titles.append(split[0])

  file_name = replace_name(raw_seq_file, '.orf.titles')

  title_file_open = open(file_name, 'w')
  for title in raw_titles:
    title_file_open.write(str(title) + '\n')
  title_file_open.close()

  hmm_out_title = replace_name(raw_seq_file, '.orf.fasta')
  subprocess.check_call('fxtract -H -f '+file_name+' '+raw_orf_title+' > '+hmm_out_title, shell=True)

def replace_name(old_title,new_suffix):
  nt = ''
  if '/' in old_title: # Check if specifying full path
    nt = old_title.split('/')[len(old_title.split('/')) - 1] # if so, chop off the path to access file name
    return nt.split('.')[0] + new_suffix # Split, and return the base with whatever suffix is wanted.
  else:
    return old_title.split('.')[0] + new_suffix # Split, and return the base with whatever suffix is wanted.

def dictionary_builder(gup_file):
  d = {
  }
  test = 1
  for line in open(gup_file, 'r'):
    list = [x for x in line.split(' ') if x]
    try:
      float(list[4])
      if list[0] != 'name' and list[1] == list[2] and float(list[4]) and float(list[len(list)-2]) > float(cl.d[0]):
        if list[0] not in d:
          d[list[0]] = []
        d[list[0]].append(list[3])
      else:
        continue
    except ValueError:
      list.pop(3)
      if list[0] != 'name' and list[0] not in d and list[1] == list[2] and float(list[4]) and float(list[len(list)-2]) > float(cl.d[0]):
        d[list[0]].append(list[3])
      else:
        continue

  classifications = []
  placed = []

  for x,y in d.iteritems():
    if x not in placed:
      classifications.append(';'.join(y))
      placed.append(x)
    else:
      continue

  otu_id = 0
  output_table = []
  unique_list = []
  output_table.append('#OTU_ID\t'+replace_name(cl.f[0], '')+'\tConsensusLineage')
  for x in classifications:
    if x not in unique_list:
      unique_list.append(x)
  for x in unique_list:
    output_table.append([str(otu_id),str(classifications.count(x)),x])
    otu_id += 1

  otu_table = open(replace_name(cl.f[0], '_otu_table.txt'), 'w')
  for line in output_table:
    if '#' in line:
      otu_table.write(line+'\n')
    else: otu_table.write('\t'.join(line)+'\n')
  otu_table.close()

  try:
    str(cl.o[0])
    subprocess.call("mv "+replace_name(cl.f[0], '')+"* "+cl.o[0]+"/ 2> /dev/null", shell = True)
  except:
    subprocess.call("mv "+replace_name(cl.f[0], '')+"* "+replace_name(cl.f[0], '')+"/ 2> /dev/null", shell = True)



 ##### Running Script #####
print intro

# Check parameters are in sensible land
if float(cl.d[0]) < float(0.5) or float(cl.d[0]) > float(1.0):
  message('Please specify a confidence level (-d) between 0.5 and 1.0! Found: %s' % cl.d[0])
  exit(1)

if cl.e[0]:
  cl.e[0] = '-E '+cl.e[0]
else:
  pass

if cl.jpplacer[0]:
  cl.jpplacer[0] =  '-j '+str(cl.jpplacer[0])
else:
  pass

if cl.jhmm[0]:
  cl.jhmm[0] = '--cpu '+str(cl.jhmm[0])
else:
  pass

try:
  cl.g
except AttributeError:
  message("The -g/--gg_database option is required in dna mode")
  exit(1)


seq_file_title = replace_name(cl.f[0], '') # Define base name for sequence file
hmm_file_title = replace_name(cl.m[0], '.hmm') # Define base name for hmm file

if hasattr(cl,'o'): # Check if an output directory has been specified
  pass
else:
  setattr(cl, 'o', [str(seq_file_title)]) # If not, just make it the base name


# Defining a list of the reads to be searched & checking the file names match.

try: # If there are forward and reverse reads
  seq_file_list = [cl.f[0], cl.r[0]] # Make a list of the names of sequences
except AttributeError: # And if just forward reads are present
  seq_file_list = [cl.f[0]] # Make a list of just the forward reads

# Check if there is an output folder name specified
try:
  str(cl.o[0])
  out_file_name = cl.o[0]
except AttributeError:
  out_file_name = replace_name(cl.f[0], '')

input_file_format = guess_sequence_file_format(seq_file_list[0])

if cl.t[0] == 'prot': # If the protein pipeline was specified
  message(datetime.now().strftime('%Y/%m/%d')) # print starting date & time
  message('Searching %s using %s..' % (seq_file_title, hmm_file_title)) # First message, searching the reads
  name_file = csv_to_titles(hmmsearch(cl.m[0], seq_file_list, input_file_format), cl.t[0]) # Create list of names that hit from the hmm search
  extract_from_raw_reads(cl.f[0], cl.m[0], name_file, input_file_format) # And extract from the original file
  message('Aligning to hmm..') # Tell user that the reads are extracted, and the alignment is proceeding
  hmmalign(cl.m[0], replace_name(cl.f[0], '.orf.fasta')) # And align
  alignment_correcter(seq_file_title+ '_conv_.fa', seq_file_title+'.aln.fasta') # And fix up the alignment file by removing the insertions
  if not hasattr(cl,'c'):
    message('No refpkg found! Stopping at alignment')
    exit(1)
  message('Placing in refpkg tree..')
  pplacer(cl.c[0], replace_name(cl.f[0], '.aln.fasta'))
  message('Creating Guppy file..')
  guppy_class(cl.c[0], replace_name(cl.f[0],'.aln.jplace'))
  message('Building OTU table..')
  dictionary_builder(replace_name(cl.f[0], '.guppy'))

if cl.t[0] == 'dna':
  date = datetime.now().strftime('%Y-%m-%d')
  message(date)
  message('Searching %s using %s..' % (seq_file_title, hmm_file_title))
  name_file = csv_to_titles(nhmmer(cl.m[0], seq_file_list, input_file_format), cl.t[0])
  extract_from_raw_reads(cl.f[0], cl.m[0], name_file, input_file_format)
  message('Aligning to database..')
  pynast(cl.f[0], cl.g)
  if not hasattr(cl,'c'):
    message('No refpkg found! Stopping at alignment')
    exit(1)
  message('Placing in refpkg tree..')
  pplacer(cl.c[0], replace_name(cl.f[0],'.aln.fasta'))
  message('Creating Guppy file..')
  guppy_class(cl.c[0], replace_name(cl.f[0], '.aln.jplace'))
  message('Building OTU table..')
  dictionary_builder(replace_name(cl.f[0], '.guppy'))


message('Finshed! Thank you for using graftM!\n')
